# ğŸ§¹ Step 3 - Scrape the Deals and the Sales

> How to manipulate and data with JavaScript from server side

<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
**Table of Contents**

- [ğŸ¯ Objective](#-objective)
- [ğŸ— Prerequisites](#%F0%9F%8F%97-prerequisites)
- [ğŸ“± How to scrape with Node.js? 1 example to do it](#-how-to-scrape-with-nodejs-1-example-to-do-it)
  - [Step 1. No code, Investigation first](#step-1-no-code-investigation-first)
  - [Step 2. Server-side with Node.js](#step-2-server-side-with-nodejs)
- [ğŸ“¦ Suggested node modules](#-suggested-node-modules)
- [ğŸ§± A complete Scraping Example for avenuedelabrique.com](#%F0%9F%A7%B1-a-complete-scraping-example-for-avenuedelabriquecom)
- [ğŸ‘©â€ğŸ’» Just tell me what to do](#%E2%80%8D-just-tell-me-what-to-do)
  - [Step 1 - Scrape `Deals` from dealabs.com](#step-1---scrape-deals-from-dealabscom)
  - [Step 2 - Scrape `Sales` from vinted.fr](#step-2---scrape-sales-from-vintedfr)
  - [Commit your modification](#commit-your-modification)
- [ğŸ›£ï¸ Related Theme and courses](#-related-theme-and-courses)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->


## ğŸ¯ Objective

**Scrape deals and sales with Node.js - for educational purpose - and use JavaScript as server-side scripting to manipulate and interact with array, objects, functions...**

## ğŸ— Prerequisites

1. Be sure **to have a clean working copy**.

    This means that you should not have any uncommitted local changes.

    ```sh
    â¯ cd /path/to/workspace/lego
    â¯ git status
    On branch master
    Your branch is up to date with 'origin/master'.

    nothing to commit, working tree clean
    ```

2. **Pull** the `master` branch to update your local with the new remote changes

    ```sh
    â¯ git remote add upstream git@github.com:92bondstreet/lego.git
    ## or â¯ git remote add upstream https://github.com/92bondstreet/lego
    â¯ git fetch upstream
    â¯ git pull --rebase upstream master
    ```

3. **Check the terminal output for the command `node sandbox.js`**

    ```sh
    â¯ cd /path/to/workspace/lego/server
    ## install dependencies
    â¯ npm install
    â¯ node sandbox.js
    ```

    <img src="./img/4-terminal.png" width="75%"/>

    **sandox** - in programming - usually refers to the execution of your programs for independent evaluation, monitoring or testing.

    It means when we call `node sandbox.js`, we want to test some piece of codes in insolation.

4. **If nothing happens or errors occur**, check your [node server installation (from Theme 2)](https://github.com/92bondstreet/inception/blob/master/themes/2.md#-just-tell-me-what-to-do)

## ğŸ“± How to scrape with Node.js? 1 example to do it

Let's try to scrape deals from website [Avenue de la brique](https://www.avenuedelabrique.com/promotions-et-bons-plans-lego).


### Step 1. No code, Investigation first

1. Browse the website
1. How does the website https://www.avenuedelabrique.com/promotions-et-bons-plans-lego work?
1. How can I access to the different deals pages?
1. What is a `Deal`? What are the given properties for a `Deal`: title, price, discount, link...?
1. Check how that you can get list of Deals: web page itself, api etc.... (Inspect Network Activity - with [Chrome DevTools for instance](https://developer.chrome.com/docs/devtools/network/) - on any browser)
1. Define the JSON object representation for a Deal
1. ...
1. ...

![devtools](./img/4-devtools-1.png)

![devtools](./img/4-devtools-2.png)

### Step 2. Server-side with Node.js

Create a module called `avenuedelabrique` that returns the list of `Deals` for a given url page of [Avenue de la brique](https://www.avenuedelabrique.com/promotions-et-bons-plans-lego).

Example of page to scrape: https://www.avenuedelabrique.com/promotions-et-bons-plans-lego


```js
// Following lines are pseudo-code
const avenuedelabrique = require('avenuedelabrique');

const deals = avenuedelabrique.scrape('https://www.avenuedelabrique.com/promotions-et-bons-plans-lego');

deals.forEach(deal => {
  console.log(deal.title);
})
```

## ğŸ“¦ Suggested node modules

* [node-fetch](https://github.com/node-fetch/node-fetch) - A light-weight module that brings Fetch API to Node.js.
* [cheerio](https://github.com/cheeriojs/cheerio) - The fast, flexible, and elegant library for parsing and manipulating HTML and XML.
* [nodemon](https://github.com/remy/nodemon) - Monitor for any changes in your node.js application and automatically restart the server - perfect for development.

## ğŸ§± A complete Scraping Example for avenuedelabrique.com

[server/websites/avenuedelabrique.js](../server/websites/avenuedelabrique.js) contains a function to scrape a given [Avenue de la brique](https://www.avenuedelabrique.com/) deals page.

To start the example, call with `node` cli or use the `Makefile` target:

```sh
â¯ cd /path/to/workspace/lego/server
â¯ node sandbox.js
â¯ node sandbox.js "https://www.avenuedelabrique.com/promotions-et-bons-plans-lego"
â¯ ## make sandbox
â¯ ## ./node_modules/.bin/nodemon sandbox.js
```


```js
const fetch = require('node-fetch');
const cheerio = require('cheerio');

/**
 * Parse webpage data response
 * @param  {String} data - html response
 * @return {Object} deal
 */
const parse = data => {
  const $ = cheerio.load(data, {'xmlMode': true});

  return $('div.prods a')
    .map((i, element) => {
      const price = parseInt(
        $(element)
          .find('span.prodl-prix span')
          .text()
      );

      const discount = Math.abs(parseInt(
        $(element)
          .find('span.prodl-reduc')
          .text()
      ));

      return {
        discount,
        price,
        'title': $(element).attr('title'),
      };
    })
    .get();
};

/**
 * Scrape a given url page
 * @param {String} url - url to parse
 * @returns 
 */
module.exports.scrape = async url => {
  const response = await fetch(url);

  if (response.ok) {
    const body = await response.text();

    return parse(body);
  }

  console.error(response);

  return null;
};
```


## ğŸ‘©â€ğŸ’» Just tell me what to do


### Step 1 - Scrape `Deals` from dealabs.com

1. How does the website https://www.dealabs.com/ work? How can I access to the different deals pages and items? What is a `Deal`? What are the given properties for a `Deal`: title, price, discount, link...?
1. **Scrape Lego deals** from Dealabs
1. **Store the list into a JSON file**

![devtools](./img/4-dealabs.png)

### Step 2 - Scrape `Sales` from vinted.fr
1. How does the website https://www.vinted.fr/ work? How can I access to the different sales pages and items? What is a `Sale`? What are the given properties for a `Sale`: title, price, link...?
1. **Scrape Vinted sales** from Vinted for a given lego set id
1. **Store the list into a JSON file**

![devtools](./img/4-vinted.png)

### Commit your modification

```sh
â¯ cd /path/to/workspace/lego
â¯ git add -A && git commit -m "feat(dealabs): scrape new deals"
```

([why following a commit message convention?](https://dev.to/chrissiemhrk/git-commit-message-5e21))

1. **Commit early, commit often**
1. Don't forget **to push before the end of the workshop**

    ```sh
    â¯ git push origin master
    ```

    **Note**: if you catch an error about authentication, [add your ssh to your github profile](https://help.github.com/articles/connecting-to-github-with-ssh/).

1. If you need some helps on git commands, read [git - the simple guide](http://rogerdudler.github.io/git-guide/)


## ğŸ›£ï¸ Related Theme and courses

* ğŸ— [Theme 2 - About Node.js](https://github.com/92bondstreet/inception/blob/master/themes/2.md#about-nodejs)
